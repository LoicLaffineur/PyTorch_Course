{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_script_mode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"1M5tsObEa17-","tags":[]},"source":["# 05. Going Modular :\n","\n","https://www.learnpytorch.io/05_pytorch_going_modular/\n","\n","**The main concept of this section is: turn useful notebook code cells into reusable Python files.**\n","\n","Useful when you work on big project and you want to do versionning (git).\n","\n","Usually you will experiment and do quick visualisation on Jupyter/Colab and then move to python script (.py)\n","\n","It depend on the person, some never use notebooks.\n"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"0XOIIUH2mDPc"},"source":["## What is script mode?\n","\n","**Script mode** uses Jupyter Notebook cell magic to turn specific cells into Python scripts.\n","\n","Synthaxe to create a Python file from a notebook cell :\n","\n","```\n","%%writefile filename.py\n","\n","[Instructions]\n","```\n","\n","You can then run this Python file on the command line with:\n","\n","```\n","python filename.py\n","```\n","\n","The main cell magic we're interested in using is `%%writefile`.\n","\n","Putting `%%writefile filename` at the top of a cell in Jupyter or Google Colab will write the contents of that cell to a specified `filename`."]},{"cell_type":"markdown","metadata":{"tags":[],"id":"AztoyQ3wmDPf"},"source":["## PyTorch in the wild\n","\n","For example, if you find a PyTorch project on GitHub, it may be structured in the following way:\n","\n","```\n","pytorch_project/\n","├── pytorch_project/\n","│   ├── data_setup.py\n","│   ├── engine.py\n","│   ├── model.py\n","│   ├── train.py\n","│   └── utils.py\n","├── models/\n","│   ├── model_1.pth\n","│   └── model_2.pth\n","└── data/\n","    ├── data_folder_1/\n","    └── data_folder_2/\n","```\n","\n","Here, the top level directory is called `pytorch_project` but you could call it whatever you want.\n","\n","Inside there's another directory called `pytorch_project` which contains several `.py` files, the purposes of these may be:\n","* `data_setup.py` - a file to prepare data (and download data if needed).\n","* `engine.py` - a file containing various training functions.\n","* `model_builder.py` or `model.py` - a file to create a PyTorch model.\n","* `train.py` - a file to leverage all other files and train a target PyTorch model.\n","* `utils.py` - a file dedicated to helpful utility functions.\n","\n","And the `models` and `data` directories could hold PyTorch models and data files respectively (due to the size of models and data files, it's unlikely you'll find the *full* versions of these on GitHub)."]},{"cell_type":"markdown","metadata":{"id":"OW_3D_fOap2I"},"source":["## 0. Creating a folder for storing Python scripts\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"K29qwItveNm9","executionInfo":{"status":"ok","timestamp":1718590845836,"user_tz":-120,"elapsed":293,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[],"source":["import os\n","\n","os.makedirs(\"going_modular\", exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"1XgXFr97bCsI"},"source":["## 1. Get data\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wl_jfPzVbGDS","outputId":"e6e0aa65-cc30-4149-f75b-00e0f350d679","executionInfo":{"status":"ok","timestamp":1718590848420,"user_tz":-120,"elapsed":1028,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Did not find data/pizza_steak_sushi directory, creating one...\n","Downloading pizza, steak, sushi data...\n","Unzipping pizza, steak, sushi data...\n"]}],"source":["import os\n","import zipfile\n","\n","from pathlib import Path\n","\n","import requests\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesn't exist, download it and prepare it...\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download pizza, steak, sushi data\n","with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","    print(\"Downloading pizza, steak, sushi data...\")\n","    f.write(request.content)\n","\n","# Unzip pizza, steak, sushi data\n","with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","    print(\"Unzipping pizza, steak, sushi data...\")\n","    zip_ref.extractall(image_path)\n","\n","# Remove zip file\n","os.remove(data_path / \"pizza_steak_sushi.zip\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qYMdiBMbde0","outputId":"875215ed-77f4-4279-cc73-294ec17e92f2","executionInfo":{"status":"ok","timestamp":1718590853890,"user_tz":-120,"elapsed":297,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(PosixPath('data/pizza_steak_sushi/train'),\n"," PosixPath('data/pizza_steak_sushi/test'))"]},"metadata":{},"execution_count":4}],"source":["# Setup train and testing paths\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"]},{"cell_type":"markdown","metadata":{"id":"RjINjcyGdwL9"},"source":["## 2. Create Datasets and DataLoaders (script mode)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"DaOJOd-QbOQk","executionInfo":{"status":"ok","timestamp":1718590875319,"user_tz":-120,"elapsed":5135,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[],"source":["from torchvision import datasets, transforms\n","\n","# Create simple transform\n","data_transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CmjK-b04du_-","outputId":"98c25074-a04a-4a91-cdb0-0c4fb1b7d634","executionInfo":{"status":"ok","timestamp":1718590878189,"user_tz":-120,"elapsed":294,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/data_setup.py\n"]}],"source":["%%writefile going_modular/data_setup.py\n","\"\"\"\n","Contains functionality for creating PyTorch DataLoaders for\n","image classification data.\n","\"\"\"\n","import os\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","    train_dir: str,\n","    test_dir: str,\n","    transform: transforms.Compose,\n","    batch_size: int,\n","    num_workers: int=NUM_WORKERS\n","):\n","  \"\"\"Creates training and testing DataLoaders.\n","\n","  Takes in a training directory and testing directory path and turns\n","  them into PyTorch Datasets and then into PyTorch DataLoaders.\n","\n","  Args:\n","    train_dir: Path to training directory.\n","    test_dir: Path to testing directory.\n","    transform: torchvision transforms to perform on training and testing data.\n","    batch_size: Number of samples per batch in each of the DataLoaders.\n","    num_workers: An integer for number of workers per DataLoader.\n","\n","  Returns:\n","    A tuple of (train_dataloader, test_dataloader, class_names).\n","    Where class_names is a list of the target classes.\n","    Example usage:\n","      train_dataloader, test_dataloader, class_names = \\\n","        = create_dataloaders(train_dir=path/to/train_dir,\n","                             test_dir=path/to/test_dir,\n","                             transform=some_transform,\n","                             batch_size=32,\n","                             num_workers=4)\n","  \"\"\"\n","  # Use ImageFolder to create dataset(s)\n","  train_data = datasets.ImageFolder(train_dir, transform=transform)\n","  test_data = datasets.ImageFolder(test_dir, transform=transform)\n","\n","  # Get class names\n","  class_names = train_data.classes\n","\n","  # Can also get class names as a dict\n","  class_dict = train_data.class_to_idx\n","\n","  # Turn images into data loaders\n","  train_dataloader = DataLoader(\n","      train_data,\n","      batch_size=batch_size,\n","      shuffle=True,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","  )\n","  test_dataloader = DataLoader(\n","      test_data,\n","      batch_size=batch_size,\n","      shuffle=False,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","  )\n","\n","  return train_dataloader, test_dataloader, class_names, class_dict"]},{"cell_type":"code","source":["# Import data_setup.py\n","from going_modular import data_setup\n","\n","# Create train/test dataloader and get class names as a list\n","train_dataloader, test_dataloader, class_names, class_dict = data_setup.create_dataloaders(train_dir=train_dir, test_dir=test_dir,transform=data_transform,batch_size=32,)"],"metadata":{"id":"TlvDKKrUAGj7","executionInfo":{"status":"ok","timestamp":1718591032182,"user_tz":-120,"elapsed":1,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJKRqXNGbnI5","outputId":"7c3af05b-ff15-470f-f7a7-c3d033925fb1","executionInfo":{"status":"ok","timestamp":1718591043802,"user_tz":-120,"elapsed":968,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Image shape: torch.Size([32, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n","Label shape: torch.Size([32])\n"]}],"source":["# Check out single image size/shape\n","img, label = next(iter(train_dataloader))\n","\n","# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n","print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n","print(f\"Label shape: {label.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"wSaDm_W7bc3y"},"source":["## 3 Making a model (TinyVGG) (script mode)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEH3bklL86hF","outputId":"f62558e6-30b8-409a-d6fa-df4ea0c42aec","executionInfo":{"status":"ok","timestamp":1718591227058,"user_tz":-120,"elapsed":282,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/model_builder.py\n"]}],"source":["%%writefile going_modular/model_builder.py\n","\"\"\"\n","Contains PyTorch model code to instantiate a TinyVGG model.\n","\"\"\"\n","import torch\n","\n","from torch import nn\n","\n","class TinyVGG(nn.Module):\n","    \"\"\"Creates the TinyVGG architecture.\n","\n","    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n","    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n","\n","    Args:\n","    input_shape: An integer indicating number of input channels.\n","    hidden_units: An integer indicating number of hidden units between layers.\n","    output_shape: An integer indicating number of output units.\n","    \"\"\"\n","    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","        super().__init__()\n","        self.conv_block_1 = nn.Sequential(\n","          nn.Conv2d(in_channels=input_shape,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(in_channels=hidden_units,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2,\n","                        stride=2)\n","        )\n","        self.conv_block_2 = nn.Sequential(\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2)\n","        )\n","        self.classifier = nn.Sequential(\n","          nn.Flatten(),\n","          # Where did this in_features shape come from?\n","          # It's because each layer of our network compresses and changes the shape of our inputs data.\n","          nn.Linear(in_features=hidden_units*13*13,\n","                    out_features=output_shape)\n","        )\n","\n","    def forward(self, x: torch.Tensor):\n","        x = self.conv_block_1(x)\n","        x = self.conv_block_2(x)\n","        x = self.classifier(x)\n","        return x\n","        # return self.classifier(self.block_2(self.block_1(x))) # <- leverage the benefits of operator fusion"]},{"cell_type":"markdown","metadata":{"id":"3-WijBWM9K2c"},"source":["Create an instance of `TinyVGG` (from the script)."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F__hbQwZ9A56","outputId":"ad63ae24-54e1-4a7c-9bde-2c413045e2d5","executionInfo":{"status":"ok","timestamp":1718591234952,"user_tz":-120,"elapsed":362,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TinyVGG(\n","  (conv_block_1): Sequential(\n","    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv_block_2): Sequential(\n","    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=1690, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":13}],"source":["import torch\n","\n","from going_modular import model_builder\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Instantiate an instance of the model from the \"model_builder.py\" script\n","torch.manual_seed(42)\n","model_1 = model_builder.TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n","                                hidden_units=10,\n","                                output_shape=len(class_names)).to(device)\n","model_1"]},{"cell_type":"markdown","metadata":{"id":"vBD-yWcp9QVT"},"source":["Do a dummy forward pass on `model_1`."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCQWeeMj9kHE","outputId":"0b60c31c-6dbd-4f0a-e0f6-a2bb2a7c3ad9","executionInfo":{"status":"ok","timestamp":1718591251704,"user_tz":-120,"elapsed":1523,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Single image shape: torch.Size([1, 3, 64, 64])\n","\n","Output logits:\n","tensor([[ 0.0208, -0.0020,  0.0095]], device='cuda:0')\n","\n","Output prediction probabilities:\n","tensor([[0.3371, 0.3295, 0.3333]], device='cuda:0')\n","\n","Output prediction label:\n","tensor([0], device='cuda:0')\n","\n","Actual label:\n","0\n"]}],"source":["# 1. Get a batch of images and labels from the DataLoader\n","img_batch, label_batch = next(iter(train_dataloader))\n","\n","# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n","img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n","print(f\"Single image shape: {img_single.shape}\\n\")\n","\n","# 3. Perform a forward pass on a single image\n","model_1.eval()\n","with torch.inference_mode():\n","    pred = model_1(img_single.to(device))\n","\n","# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n","print(f\"Output logits:\\n{pred}\\n\")\n","print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n","print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n","print(f\"Actual label:\\n{label_single}\")"]},{"cell_type":"markdown","metadata":{"id":"tw_nYa4kfQeI"},"source":["## 4 Creating `train_step()` and `test_step()` functions and `train()` to combine them (script mode)   \n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d47bhfY3fVq5","outputId":"cd71b1f5-2f7a-46e7-97a0-0c9fdec021e8","executionInfo":{"status":"ok","timestamp":1718591344309,"user_tz":-120,"elapsed":290,"user":{"displayName":"Loïc","userId":"07474836273467953652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/engine.py\n"]}],"source":["%%writefile going_modular/engine.py\n","\"\"\"\n","Contains functions for training and testing a PyTorch model.\n","\"\"\"\n","from typing import Dict, List, Tuple\n","\n","import torch\n","\n","from tqdm.auto import tqdm\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","    \"\"\"Trains a PyTorch model for a single epoch.\n","\n","    Turns a target PyTorch model to training mode and then\n","    runs through all of the required training steps (forward\n","    pass, loss calculation, optimizer step).\n","\n","    Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy). For example:\n","\n","    (0.1112, 0.8743)\n","    \"\"\"\n","    # Put model in train mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","\n","    # Loop through data loader data batches\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Send data to target device\n","        X, y = X.to(device), y.to(device)\n","\n","        # 1. Forward pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate  and accumulate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item()\n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Loss backward\n","        loss.backward()\n","\n","        # 5. Optimizer step\n","        optimizer.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","    return train_loss, train_acc\n","\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","    \"\"\"Tests a PyTorch model for a single epoch.\n","\n","    Turns a target PyTorch model to \"eval\" mode and then performs\n","    a forward pass on a testing dataset.\n","\n","    Args:\n","    model: A PyTorch model to be tested.\n","    dataloader: A DataLoader instance for the model to be tested on.\n","    loss_fn: A PyTorch loss function to calculate loss on the test data.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A tuple of testing loss and testing accuracy metrics.\n","    In the form (test_loss, test_accuracy). For example:\n","\n","    (0.0223, 0.8985)\n","    \"\"\"\n","    # Put model in eval mode\n","    model.eval()\n","\n","    # Setup test loss and test accuracy values\n","    test_loss, test_acc = 0, 0\n","\n","    # Turn on inference context manager\n","    with torch.inference_mode():\n","        # Loop through DataLoader batches\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Send data to target device\n","            X, y = X.to(device), y.to(device)\n","\n","            # 1. Forward pass\n","            test_pred_logits = model(X)\n","\n","            # 2. Calculate and accumulate loss\n","            loss = loss_fn(test_pred_logits, y)\n","            test_loss += loss.item()\n","\n","            # Calculate and accumulate accuracy\n","            test_pred_labels = test_pred_logits.argmax(dim=1)\n","            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    test_loss = test_loss / len(dataloader)\n","    test_acc = test_acc / len(dataloader)\n","    return test_loss, test_acc\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List[float]]:\n","    \"\"\"Trains and tests a PyTorch model.\n","\n","    Passes a target PyTorch models through train_step() and test_step()\n","    functions for a number of epochs, training and testing the model\n","    in the same epoch loop.\n","\n","    Calculates, prints and stores evaluation metrics throughout.\n","\n","    Args:\n","    model: A PyTorch model to be trained and tested.\n","    train_dataloader: A DataLoader instance for the model to be trained on.\n","    test_dataloader: A DataLoader instance for the model to be tested on.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","    epochs: An integer indicating how many epochs to train for.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A dictionary of training and testing loss as well as training and\n","    testing accuracy metrics. Each metric has a value in a list for\n","    each epoch.\n","    In the form: {train_loss: [...],\n","              train_acc: [...],\n","              test_loss: [...],\n","              test_acc: [...]}\n","    For example if training for epochs=2:\n","             {train_loss: [2.0616, 1.0537],\n","              train_acc: [0.3945, 0.3945],\n","              test_loss: [1.2641, 1.5706],\n","              test_acc: [0.3400, 0.2973]}\n","    \"\"\"\n","    # Create empty results dictionary\n","    results = {\"train_loss\": [],\n","               \"train_acc\": [],\n","               \"test_loss\": [],\n","               \"test_acc\": []\n","    }\n","\n","    # Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer,\n","                                          device=device)\n","        test_loss, test_acc = test_step(model=model,\n","          dataloader=test_dataloader,\n","          loss_fn=loss_fn,\n","          device=device)\n","\n","        # Print out what's happening\n","        print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","        )\n","\n","        # Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","    # Return the filled results at the end of the epochs\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"F7SnPGOfc_Wc"},"source":["## 5 Creating a function to save the model (script mode)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20LC4xwN_2ZT","outputId":"30852196-8138-4f9e-9f43-578dc6277682"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting going_modular/utils.py\n"]}],"source":["%%writefile going_modular/utils.py\n","\"\"\"\n","Contains various utility functions for PyTorch model training and saving.\n","\"\"\"\n","from pathlib import Path\n","\n","import torch\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","    \"\"\"Saves a PyTorch model to a target directory.\n","\n","    Args:\n","    model: A target PyTorch model to save.\n","    target_dir: A directory for saving the model to.\n","    model_name: A filename for the saved model. Should include\n","      either \".pth\" or \".pt\" as the file extension.\n","\n","    Example usage:\n","    save_model(model=model_0,\n","               target_dir=\"models\",\n","               model_name=\"05_going_modular_tingvgg_model.pth\")\n","    \"\"\"\n","    # Create target directory\n","    target_dir_path = Path(target_dir)\n","    target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","    # Create model save path\n","    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","    model_save_path = target_dir_path / model_name\n","\n","    # Save the model state_dict()\n","    print(f\"[INFO] Saving model to: {model_save_path}\")\n","    torch.save(obj=model.state_dict(),\n","             f=model_save_path)"]},{"cell_type":"markdown","metadata":{"id":"Md_CmXTvfkOz"},"source":["## 6 Train, evaluate and save the model (script mode)\n","\n","Let's combine all of our modular files into a single script `train.py`.\n","\n","This will allow us to run all of the functions we've written with a single line of code on the command line:\n","\n","`python going_modular/train.py`\n","\n","Or if we're running it in a notebook:\n","\n","`!python going_modular/train.py`\n","\n","We'll go through the following steps:\n","1. Import the various dependencies, namely `torch`, `os`, `torchvision.transforms` and all of the scripts from the `going_modular` directory, `data_setup`, `engine`, `model_builder`, `utils`.\n","  * **Note:** Since `train.py` will be *inside* the `going_modular` directory, we can import the other modules via `import ...` rather than `from going_modular import ...`.\n","2. Setup various hyperparameters such as batch size, number of epochs, learning rate and number of hidden units\n","3. Setup the training and test directories.\n","4. Setup device-agnostic code.\n","5. Create the necessary data transforms.\n","6. Create the DataLoaders using `data_setup.py`.\n","7. Create the model using `model_builder.py`.\n","8. Setup the loss function and optimizer.\n","9. Train the model using `engine.py`.\n","10. Save the model using `utils.py`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XnG2l4zf2Ei","outputId":"84f67ba0-ddaf-45a2-9a71-a37cf3d1ca88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting going_modular/train.py\n"]}],"source":["%%writefile going_modular/train.py\n","\"\"\"\n","Trains a PyTorch image classification model using device-agnostic code.\n","\"\"\"\n","\n","import os\n","\n","import torch\n","\n","from torchvision import transforms\n","\n","import data_setup, engine, model_builder, utils\n","\n","\n","# Setup hyperparameters\n","NUM_EPOCHS = 5\n","BATCH_SIZE = 32\n","HIDDEN_UNITS = 10\n","LEARNING_RATE = 0.001\n","\n","# Setup directories\n","train_dir = \"data/pizza_steak_sushi/train\"\n","test_dir = \"data/pizza_steak_sushi/test\"\n","\n","# Setup target device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Create transforms\n","data_transform = transforms.Compose([\n","  transforms.Resize((64, 64)),\n","  transforms.ToTensor()\n","])\n","\n","# Create DataLoaders with help from data_setup.py\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir=test_dir,\n","    transform=data_transform,\n","    batch_size=BATCH_SIZE\n",")\n","\n","# Create model with help from model_builder.py\n","model = model_builder.TinyVGG(\n","    input_shape=3,\n","    hidden_units=HIDDEN_UNITS,\n","    output_shape=len(class_names)\n",").to(device)\n","\n","# Set loss and optimizer\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),\n","                             lr=LEARNING_RATE)\n","\n","# Start training with help from engine.py\n","engine.train(model=model,\n","             train_dataloader=train_dataloader,\n","             test_dataloader=test_dataloader,\n","             loss_fn=loss_fn,\n","             optimizer=optimizer,\n","             epochs=NUM_EPOCHS,\n","             device=device)\n","\n","# Save the model with help from utils.py\n","utils.save_model(model=model,\n","                 target_dir=\"models\",\n","                 model_name=\"05_going_modular_script_mode_tinyvgg_model.pth\")"]},{"cell_type":"markdown","metadata":{"id":"HHnPm-w7CjXT"},"source":["Now our final directory structure looks like:\n","```\n","data/\n","  pizza_steak_sushi/\n","    train/\n","      pizza/\n","        train_image_01.jpeg\n","        train_image_02.jpeg\n","        ...\n","      steak/\n","      sushi/\n","    test/\n","      pizza/\n","        test_image_01.jpeg\n","        test_image_02.jpeg\n","        ...\n","      steak/\n","      sushi/\n","going_modular/\n","  data_setup.py\n","  engine.py\n","  model_builder.py\n","  train.py\n","  utils.py\n","models/\n","  saved_model.pth\n","```\n","\n","Now let's run our `train.py` file from the command line with:\n","\n","```\n","!python going_modular/train.py\n","```\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eVtanbSCjFj","outputId":"9c90d0d8-9b44-4558-b74d-292729eca1e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["  0%|                                                     | 0/5 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.1131 | train_acc: 0.2852 | test_loss: 1.1138 | test_acc: 0.2604\n"," 20%|█████████                                    | 1/5 [00:01<00:04,  1.06s/it]Epoch: 2 | train_loss: 1.0851 | train_acc: 0.4102 | test_loss: 1.1238 | test_acc: 0.1979\n"," 40%|██████████████████                           | 2/5 [00:01<00:02,  1.20it/s]Epoch: 3 | train_loss: 1.0837 | train_acc: 0.4141 | test_loss: 1.1459 | test_acc: 0.1979\n"," 60%|███████████████████████████                  | 3/5 [00:02<00:01,  1.33it/s]Epoch: 4 | train_loss: 1.1104 | train_acc: 0.2930 | test_loss: 1.1318 | test_acc: 0.1979\n"," 80%|████████████████████████████████████         | 4/5 [00:03<00:00,  1.40it/s]Epoch: 5 | train_loss: 1.0833 | train_acc: 0.2930 | test_loss: 1.0883 | test_acc: 0.3712\n","100%|█████████████████████████████████████████████| 5/5 [00:03<00:00,  1.35it/s]\n","[INFO] Saving model to: models/05_going_modular_script_mode_tinyvgg_model.pth\n"]}],"source":["!python going_modular/train.py"]},{"cell_type":"markdown","source":["# Exercices !\n","https://www.learnpytorch.io/05_pytorch_going_modular/#exercises\n","\n","Solution : https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/05_pytorch_going_modular_exercise_solutions.ipynb"],"metadata":{"id":"cgW54xrVCTDl"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["1M5tsObEa17-"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}